{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4179eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "753925e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Text':['Learnbay teaches NLP',\n",
    "                        'NLP is in demand in market',\n",
    "                        'We have to learn NLP']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "004ef9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Learnbay teaches NLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NLP is in demand in market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We have to learn NLP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Text\n",
       "0        Learnbay teaches NLP\n",
       "1  NLP is in demand in market\n",
       "2        We have to learn NLP"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5b1bba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b38f604",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4490986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_true=cv.fit_transform(df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a13ab89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0],\n",
       "       [1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_true.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b1d3459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1883bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learnbay': 5,\n",
       " 'teaches': 8,\n",
       " 'nlp': 7,\n",
       " 'is': 3,\n",
       " 'in': 2,\n",
       " 'demand': 0,\n",
       " 'market': 6,\n",
       " 'we': 10,\n",
       " 'have': 1,\n",
       " 'to': 9,\n",
       " 'learn': 4}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d3c5ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_1=CountVectorizer(binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d72908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_false=cv_1.fit_transform(df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e947c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0],\n",
       "       [1, 0, 2, 1, 0, 0, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_false.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fb4b7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1=pd.DataFrame({'Text':['This Pasta is Tasty', \n",
    "                             'This Pasta is not Tasty',\n",
    "                          'Pasty is delecious',\n",
    "                             'I like pasta very much',\n",
    "                           'Pasta is good but cost is little high',\n",
    "                             'Pasta tast is good and affordable',\n",
    "    'Pasta test is really nice however price is not an affordable']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0825fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This Pasta is Tasty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This Pasta is not Tasty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pasty is delecious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I like pasta very much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pasta is good but cost is little high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pasta tast is good and affordable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pasta test is really nice however price is not...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0                                This Pasta is Tasty\n",
       "1                            This Pasta is not Tasty\n",
       "2                                 Pasty is delecious\n",
       "3                             I like pasta very much\n",
       "4              Pasta is good but cost is little high\n",
       "5                  Pasta tast is good and affordable\n",
       "6  Pasta test is really nice however price is not..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3bebaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_1_gram=CountVectorizer(ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daeaa899",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_uni_gram=cv_1_gram.fit_transform(df_1['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ab32e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "        1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "        1, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 1, 1, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "        0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_uni_gram.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c65c5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 22, 'pasta': 15, 'is': 9, 'tasty': 20, 'not': 14, 'pasty': 16, 'delecious': 5, 'like': 10, 'very': 23, 'much': 12, 'good': 6, 'but': 3, 'cost': 4, 'little': 11, 'high': 7, 'tast': 19, 'and': 2, 'affordable': 0, 'test': 21, 'really': 18, 'nice': 13, 'however': 8, 'price': 17, 'an': 1}\n"
     ]
    }
   ],
   "source": [
    "print(cv_1_gram.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9ca4261",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_2_gram=CountVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b735c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_bi_gram=cv_2_gram.fit_transform(df_1['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ee0b7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 49, 'pasta': 33, 'is': 16, 'tasty': 46, 'this pasta': 50, 'pasta is': 34, 'is tasty': 22, 'not': 30, 'is not': 20, 'not tasty': 32, 'pasty': 38, 'delecious': 9, 'pasty is': 39, 'is delecious': 17, 'like': 23, 'very': 51, 'much': 27, 'like pasta': 24, 'pasta very': 37, 'very much': 52, 'good': 10, 'but': 5, 'cost': 7, 'little': 25, 'high': 13, 'is good': 18, 'good but': 12, 'but cost': 6, 'cost is': 8, 'is little': 19, 'little high': 26, 'tast': 44, 'and': 3, 'affordable': 0, 'pasta tast': 35, 'tast is': 45, 'good and': 11, 'and affordable': 4, 'test': 47, 'really': 42, 'nice': 28, 'however': 14, 'price': 40, 'an': 1, 'pasta test': 36, 'test is': 48, 'is really': 21, 'really nice': 43, 'nice however': 29, 'however price': 15, 'price is': 41, 'not an': 31, 'an affordable': 2}\n"
     ]
    }
   ],
   "source": [
    "print(cv_2_gram.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c408b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 2, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "        0, 0, 0, 1, 1, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_bi_gram.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "072ca9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_2_2_gram=CountVectorizer(ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e783302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_2_2_gram=cv_2_2_gram.fit_transform(df_1['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41efaf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this pasta': 27, 'pasta is': 18, 'is tasty': 12, 'is not': 10, 'not tasty': 17, 'pasty is': 22, 'is delecious': 7, 'like pasta': 13, 'pasta very': 21, 'very much': 28, 'is good': 8, 'good but': 5, 'but cost': 2, 'cost is': 3, 'is little': 9, 'little high': 14, 'pasta tast': 19, 'tast is': 25, 'good and': 4, 'and affordable': 1, 'pasta test': 20, 'test is': 26, 'is really': 11, 'really nice': 24, 'nice however': 15, 'however price': 6, 'price is': 23, 'not an': 16, 'an affordable': 0}\n"
     ]
    }
   ],
   "source": [
    "print(cv_2_2_gram.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4b6eaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_3_gram=CountVectorizer(ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e0fc0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_3_gram=cv_3_gram.fit_transform(df_1['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7f477f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 74, 'pasta': 47, 'is': 21, 'tasty': 70, 'this pasta': 75, 'pasta is': 48, 'is tasty': 33, 'this pasta is': 76, 'pasta is tasty': 51, 'not': 43, 'is not': 28, 'not tasty': 46, 'pasta is not': 50, 'is not tasty': 30, 'pasty': 58, 'delecious': 11, 'pasty is': 59, 'is delecious': 22, 'pasty is delecious': 60, 'like': 34, 'very': 77, 'much': 39, 'like pasta': 35, 'pasta very': 56, 'very much': 78, 'like pasta very': 36, 'pasta very much': 57, 'good': 12, 'but': 5, 'cost': 8, 'little': 37, 'high': 17, 'is good': 23, 'good but': 15, 'but cost': 6, 'cost is': 9, 'is little': 26, 'little high': 38, 'pasta is good': 49, 'is good but': 25, 'good but cost': 16, 'but cost is': 7, 'cost is little': 10, 'is little high': 27, 'tast': 67, 'and': 3, 'affordable': 0, 'pasta tast': 52, 'tast is': 68, 'good and': 13, 'and affordable': 4, 'pasta tast is': 53, 'tast is good': 69, 'is good and': 24, 'good and affordable': 14, 'test': 71, 'really': 64, 'nice': 40, 'however': 18, 'price': 61, 'an': 1, 'pasta test': 54, 'test is': 72, 'is really': 31, 'really nice': 65, 'nice however': 41, 'however price': 19, 'price is': 62, 'not an': 44, 'an affordable': 2, 'pasta test is': 55, 'test is really': 73, 'is really nice': 32, 'really nice however': 66, 'nice however price': 42, 'however price is': 20, 'price is not': 63, 'is not an': 29, 'not an affordable': 45}\n"
     ]
    }
   ],
   "source": [
    "print(cv_3_gram.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45598498",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_3_3_gram=CountVectorizer(ngram_range=(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f4a6aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_3_gram=cv_3_3_gram.fit_transform(df_1['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c5102c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this pasta is': 25, 'pasta is tasty': 16, 'pasta is not': 15, 'is not tasty': 9, 'pasty is delecious': 20, 'like pasta very': 11, 'pasta very much': 19, 'pasta is good': 14, 'is good but': 6, 'good but cost': 3, 'but cost is': 0, 'cost is little': 1, 'is little high': 7, 'pasta tast is': 17, 'tast is good': 23, 'is good and': 5, 'good and affordable': 2, 'pasta test is': 18, 'test is really': 24, 'is really nice': 10, 'really nice however': 22, 'nice however price': 12, 'however price is': 4, 'price is not': 21, 'is not an': 8, 'not an affordable': 13}\n"
     ]
    }
   ],
   "source": [
    "print(cv_3_3_gram.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32130ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0],\n",
       "       [1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "        1, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_3_gram.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f31fc7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d5b8d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c8d80d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf=tfidf.fit_transform(df_1['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41badc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.35120361,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.35120361, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.61372308, 0.        , 0.61372308, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.29932725,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.52306991,\n",
       "        0.29932725, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.52306991, 0.        , 0.52306991, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.67030489, 0.        , 0.        , 0.        , 0.3184065 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.67030489, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.55679067, 0.        , 0.55679067, 0.        , 0.        ,\n",
       "        0.26448527, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.55679067],\n",
       "       [0.        , 0.        , 0.        , 0.41461129, 0.41461129,\n",
       "        0.        , 0.34416298, 0.41461129, 0.        , 0.39389517,\n",
       "        0.        , 0.41461129, 0.        , 0.        , 0.        ,\n",
       "        0.19694759, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.42418906, 0.        , 0.51101828, 0.        , 0.        ,\n",
       "        0.        , 0.42418906, 0.        , 0.        , 0.24274258,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.24274258, 0.        , 0.        , 0.        , 0.51101828,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.28461177, 0.34287027, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.34287027, 0.32573871,\n",
       "        0.        , 0.        , 0.        , 0.34287027, 0.28461177,\n",
       "        0.16286935, 0.        , 0.34287027, 0.34287027, 0.        ,\n",
       "        0.        , 0.34287027, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63445169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 22, 'pasta': 15, 'is': 9, 'tasty': 20, 'not': 14, 'pasty': 16, 'delecious': 5, 'like': 10, 'very': 23, 'much': 12, 'good': 6, 'but': 3, 'cost': 4, 'little': 11, 'high': 7, 'tast': 19, 'and': 2, 'affordable': 0, 'test': 21, 'really': 18, 'nice': 13, 'however': 8, 'price': 17, 'an': 1}\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "94a423b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_4_gram=TfidfVectorizer(ngram_range=(1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5b559571",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_4=tfidf_4_gram.fit_transform(df_1['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "88506492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 92, 'pasta': 57, 'is': 25, 'tasty': 87, 'this pasta': 93, 'pasta is': 58, 'is tasty': 41, 'this pasta is': 94, 'pasta is tasty': 63, 'this pasta is tasty': 96, 'not': 53, 'is not': 34, 'not tasty': 56, 'pasta is not': 61, 'is not tasty': 37, 'this pasta is not': 95, 'pasta is not tasty': 62, 'pasty': 72, 'delecious': 13, 'pasty is': 73, 'is delecious': 26, 'pasty is delecious': 74, 'like': 42, 'very': 97, 'much': 48, 'like pasta': 43, 'pasta very': 70, 'very much': 98, 'like pasta very': 44, 'pasta very much': 71, 'like pasta very much': 45, 'good': 14, 'but': 5, 'cost': 9, 'little': 46, 'high': 20, 'is good': 27, 'good but': 17, 'but cost': 6, 'cost is': 10, 'is little': 32, 'little high': 47, 'pasta is good': 59, 'is good but': 30, 'good but cost': 18, 'but cost is': 7, 'cost is little': 11, 'is little high': 33, 'pasta is good but': 60, 'is good but cost': 31, 'good but cost is': 19, 'but cost is little': 8, 'cost is little high': 12, 'tast': 83, 'and': 3, 'affordable': 0, 'pasta tast': 64, 'tast is': 84, 'good and': 15, 'and affordable': 4, 'pasta tast is': 65, 'tast is good': 85, 'is good and': 28, 'good and affordable': 16, 'pasta tast is good': 66, 'tast is good and': 86, 'is good and affordable': 29, 'test': 88, 'really': 79, 'nice': 49, 'however': 21, 'price': 75, 'an': 1, 'pasta test': 67, 'test is': 89, 'is really': 38, 'really nice': 80, 'nice however': 50, 'however price': 22, 'price is': 76, 'not an': 54, 'an affordable': 2, 'pasta test is': 68, 'test is really': 90, 'is really nice': 39, 'really nice however': 81, 'nice however price': 51, 'however price is': 23, 'price is not': 77, 'is not an': 35, 'not an affordable': 55, 'pasta test is really': 69, 'test is really nice': 91, 'is really nice however': 40, 'really nice however price': 82, 'nice however price is': 52, 'however price is not': 24, 'price is not an': 78, 'is not an affordable': 36}\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_4_gram.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c2a1ec81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.18336634, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.38602023, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.18336634, 0.27389289, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.38602023, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.32042994, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.32042994, 0.32042994, 0.32042994,\n",
       "        0.        , 0.38602023, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.14954989, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.26133621,\n",
       "        0.        , 0.        , 0.31483033, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.26133621, 0.        ,\n",
       "        0.        , 0.31483033, 0.14954989, 0.22338153, 0.        ,\n",
       "        0.        , 0.31483033, 0.31483033, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.26133621, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.26133621, 0.26133621, 0.26133621,\n",
       "        0.31483033, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.43745178, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.20779722, 0.43745178, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.43745178, 0.43745178, 0.43745178,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.32923175, 0.32923175, 0.32923175,\n",
       "        0.32923175, 0.        , 0.        , 0.32923175, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15639082, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.32923175, 0.32923175, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.32923175, 0.32923175],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.20847034, 0.20847034, 0.20847034, 0.20847034, 0.20847034,\n",
       "        0.20847034, 0.20847034, 0.20847034, 0.        , 0.17304829,\n",
       "        0.        , 0.        , 0.20847034, 0.20847034, 0.20847034,\n",
       "        0.20847034, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.19805409, 0.        , 0.17304829, 0.        , 0.        ,\n",
       "        0.20847034, 0.20847034, 0.20847034, 0.20847034, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.20847034, 0.20847034, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.09902704, 0.14791594, 0.20847034,\n",
       "        0.20847034, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.21071692, 0.        , 0.        , 0.25384954, 0.25384954,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.21071692,\n",
       "        0.25384954, 0.25384954, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.12058295, 0.        , 0.21071692, 0.25384954, 0.25384954,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.12058295, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.25384954,\n",
       "        0.25384954, 0.25384954, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.25384954, 0.25384954,\n",
       "        0.25384954, 0.25384954, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.13992022, 0.16856113, 0.16856113, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.16856113, 0.16856113, 0.16856113, 0.16856113,\n",
       "        0.16013895, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.13992022,\n",
       "        0.16856113, 0.16856113, 0.        , 0.16856113, 0.16856113,\n",
       "        0.16856113, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16856113,\n",
       "        0.16856113, 0.16856113, 0.16856113, 0.13992022, 0.16856113,\n",
       "        0.16856113, 0.        , 0.08006948, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.16856113, 0.16856113, 0.16856113,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.16856113, 0.16856113, 0.16856113, 0.16856113, 0.16856113,\n",
       "        0.16856113, 0.16856113, 0.16856113, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.16856113, 0.16856113,\n",
       "        0.16856113, 0.16856113, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_4.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93eb544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
